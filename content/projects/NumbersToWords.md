---
date: '2024-11-01'
title: 'Number to Words Translation using Seq2Seq'
github: 'https://github.com/sej07/Number-to-Words-Seq2Seq'
external: ''
tech:
  - TensorFlow
  - Keras
  - LSTM
  - Seq2Seq
  - NLP
showInProjects: true
---

Implemented a sequence-to-sequence model with stacked LSTM encoder-decoder architecture to translate numbers into their word equivalents. Built custom synthetic dataset with text preprocessing and tokenization pipeline. Trained with teacher forcing for 150 epochs, demonstrating how encoder-decoder models learn structured sequence translations without attention mechanisms.